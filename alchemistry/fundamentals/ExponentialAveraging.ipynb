{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a119f00b-d8c3-48f8-a92c-73287764e3ea",
   "metadata": {},
   "source": [
    "(exp_avg)=\n",
    "# Exponential Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303403d9-8584-4d41-bfe7-4d8a4daf4522",
   "metadata": {},
   "source": [
    "Exponential Averaging (EXP) is one of the earliest free energy methods available to researchers. Mostly used to evaluate between only two states of interest, it has an exact solution where as many other methods require approximations. Other names for this technique are the \"Zwanzig relationship\" (named after the person who first derived it){cite}`Zwanzig1954` and \"free energy perturbation (FEP).\" To avoid confusion, the latter term should be avoided as it can easily be confused with other definitions in the scientific field.\n",
    "\n",
    "## Derivation\n",
    "Starting from the [statistical relation for free energy](core_eq) of\n",
    "\n",
    "$ \\displaystyle A = -\\beta^{-1} \\mathrm{ln}\\, Q$\n",
    "\n",
    "the free energy difference between two states with potentials $U_0(\\vec{q})$ and $U_1(\\vec{q})$ is simply\n",
    "\n",
    "$ \\displaystyle \\Delta A_{10} = A_1 - A_0 = -\\beta^{-1} \\left[\\mathrm{ln}(Q_1) - \\mathrm{ln}(Q_0)\\right] = -\\beta^{-1} \\mathrm{ln}\\left[\\frac{Q_1}{Q_0}\\right]  $.\n",
    "\n",
    "By then adding and subtracting $e^{-\\beta U_0(\\vec{q})}$ from the integral in the partition function in the numerator, we get:\n",
    "\n",
    "$ \\Delta A_{10} = -\\beta^{-1} \\mathrm{ln} \\left[\\frac{\\int e^{-\\beta \\left(U_1(\\vec{q})-U_0(\\vec{q})+U_0(\\vec{q})\\right)} d\\vec{q}}{Q_0}\\right] = -\\beta^{-1} \\mathrm{ln} \\left[\\frac{\\int e^{-\\beta \\left(U_1(\\vec{q})-U_0(\\vec{q})\\right)} e^{-\\beta U_0(\\vec{q})} d\\vec{q}}{Q_0}\\right]$\n",
    "\n",
    "which gives the final relationship of:\n",
    "\n",
    "$ \\displaystyle \\Delta A_{10} = -\\beta^{-1} \\mathrm{ln} \\left\\langle e^{-\\beta \\left(U_1(\\vec{q})-U_0(\\vec{q})\\right)} \\right\\rangle_0 = -\\beta^{-1} \\mathrm{ln} \\left\\langle e^{-\\beta \\Delta U(\\vec{q})} \\right\\rangle_0 $\n",
    "\n",
    "\n",
    "This can also be derived from the technique of importance sampling. \n",
    "\n",
    "First, the concept of Monte Carlo integration states that if we want to estimate some multidimensional expectation value $\\langle O \\rangle_i = \\int O(\\vec{q})p(\\vec{q}) d\\vec{q}$, where $p(\\vec{q})$ is a normalized distribution, it can be estimated from $N$ samples from the probability distribution $p(\\vec{q})$ as  $\\sum_{i=1}^{N} O(q_i)$.  Note that this works if we do not know the normalizing constant; we only need to draw samples proportional to $p\\vec{q}$. \n",
    "\n",
    "Importance sampling states that if we have two distributions $p_1(\\vec{q})$ and $p_2(\\vec{q})$, then we can write the integral as:\n",
    "\n",
    "$ \\displaystyle \\int O(\\vec{q}) p_1(\\vec{q}) d\\vec{q} = \\int O(\\vec{q}) p_2(\\vec{q}) \\left(\\frac{p_1(\\vec{q})}{p_2(\\vec{q})}\\right) d\\vec{q} $  \n",
    "Which can be approximated by the sum $\\sum_{i=1}^{N} O(\\vec{q}_i) \\left(\\frac{p_1(\\vec{q})}{p_2(\\vec{q})}\\right)$, which is a estimate of the expectation value $\\langle O \\rangle_i$, but estimated with samples from $p_2$.  \n",
    "\n",
    "If we now have two normalized Boltzmann distributions $\\rho_1(\\vec{q}) = \\frac{e^{-\\beta U_1(\\vec{q})}}{Q_1} = e^{-\\beta A_1 - \\beta U_1}$ and $\\rho_2(\\vec{q}) = \\frac{e^{\\beta U_2(\n",
    "\\vec{q})}}{Q_2} = e^{\\beta A_1 - \\beta U_1}$, then we can write:\n",
    "\n",
    "$ \\displaystyle \\langle O(\\vec{q}) \\rangle_1 = \n",
    "\\left\\langle O(\\vec{q}) \\frac{e^{\\beta A_1 -\\beta U_1(\\vec{q})}}{e^{\\beta A_2 -\\beta U_2(\\vec{q})}} \\right\\rangle_2 = \\left\\langle O(\\vec{q}) e^{\\beta A_1-A_2 -\\beta U_1(\\vec{q})-U_2(\\vec{q})}\\right\\rangle_2$\n",
    "\n",
    "This is a general formula for estimating the expectation value of $\\langle O(\\vec{q} \\rangle_1$ with samples from $p_2$, but does not tell us how what the value of $\\Delta A = A_1-A_2$ is.  However $\\Delta A$ is independent of the position.  Let us use the special case of $O(\\vec{q})= 1$ (i.e. the constant 1).  Clearly, $\\langle 1 \\rangle_1 =1$ -- the average must be 1 because every single value is 1!  We then get: \n",
    "\n",
    "$ \\displaystyle 1 =  \\left \\langle e^{\\beta \\Delta A -\\beta (U_1(\\vec{q})-U_2)(\\vec{q})}\\right\\rangle_2$\n",
    "\n",
    "$ \\displaystyle e^{-\\beta \\Delta A} =  \\left \\langle  e^{-\\beta (U_1(\\vec{q})-U_2(\\vec{q})}\\right\\rangle_2 \\approx \\sum_{i=1}^N e^{-\\beta (U_1(\\vec{q})-U_2(\\vec{q}))}$, where the $\\vec{q}$ are sampled from $p_2$. \n",
    "\n",
    "This is of course symmetric, so $A_2-A_1 = -\\Delta A$ can be computed from samples from $p_1$, but recomputing the energies from state 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a1d895-a10e-44a4-8aef-fda2a3377157",
   "metadata": {},
   "source": [
    "## Estimating Free Energies and variance of EXP\n",
    "Because EXP is a two state method, estimating free energies is straightforward and each state's individual variance is additive because there are only two.\n",
    "\n",
    "For any given EXP calculation, you only need the $ k $ and one of the $ k \\pm 1 $ states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41386621-8255-4d22-b1b5-9ac3cb27fd37",
   "metadata": {},
   "source": [
    "## Limitations of EXP\n",
    "Although this is an exact solution and one of the simplest methods to understand, it is also one of the poorest methods in terms of efficiency. The EXP method does not converge quickly with number of samples, and even converged results show a very poor [phase space overlap](Intermediate_States){cite}`Shirts2005,Lu2003` For these reasons, unless the potential energy distributions for all $\\vec{q}$ are known to be small (on the order of 1-2 $k_B T$), then **EXP should not be used.**\n",
    "\n",
    "There are a few explicit cases where EXP is beneficial:\n",
    "* Calculating the free energy difference between a cheap potential and a more expensive potential that are very close to each other. One can simulate at the cheap parameters and estimate results at the expensive parameters.\n",
    "* If the unsampled \"target\" state's phase space is a subset of the simulated state, then EXP is much more accurate;{cite}`Lu2003,Lu1999,Wu2005a,Wu2005b,Jarzynski2006` a rigid molecule insertion into a dense fluid is one such example.\n",
    "\n",
    "Despite these cases, it is challenging to know the phase spaces *a priori* and even then, its not known which state is the best to sample from.\n",
    "\n",
    "Lastly, EXP only uses two states worth of data for all of its calculations, limiting the ability to efficiently estimate more states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aad463-4f95-4da6-b209-33bf28fbfb58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
